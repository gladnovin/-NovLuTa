{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6ba9fb3-511a-49a4-ab31-505bf2d85c3a",
      "metadata": {
        "id": "e6ba9fb3-511a-49a4-ab31-505bf2d85c3a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "llama2_13b = \"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\"\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94307413-e4b1-4e57-8438-311530cd384c",
      "metadata": {
        "id": "94307413-e4b1-4e57-8438-311530cd384c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drugLibTrain_raw.tsv', delimiter=\"\\t\")\n",
        "drugs  = sorted(df[\"urlDrugName\"].unique())\n",
        "\n",
        "tmp = df.groupby([\"condition\"])[\"condition\"].count().sort_values(ascending=False).head(50).to_frame()\n",
        "tmp.columns = ['count']\n",
        "\n",
        "conditions  = sorted(tmp.reset_index()['condition'])\n",
        "\n",
        "df2=pd.read_csv('drugs_for_common_treatments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3ddc82-2f5d-4772-b638-194bef60d027",
      "metadata": {
        "id": "6a3ddc82-2f5d-4772-b638-194bef60d027"
      },
      "outputs": [],
      "source": [
        "\n",
        "def md(t):\n",
        "  display(Markdown(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8727ef36-65ef-483c-9734-556266839660",
      "metadata": {
        "id": "8727ef36-65ef-483c-9734-556266839660"
      },
      "outputs": [],
      "source": [
        "import replicate\n",
        "# langchain setup\n",
        "from langchain.llms import Replicate\n",
        "# Use the Llama 2 model hosted on Replicate\n",
        "# Temperature: Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic, 0.75 is a good starting value\n",
        "# top_p: When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less likely tokens\n",
        "# max_new_tokens: Maximum number of tokens to generate. A word is generally 2-3 tokens\n",
        "llama_model = Replicate(\n",
        "    model=llama2_13b,\n",
        "    model_kwargs={\"temperature\": 0.5,\"top_p\": 1, \"max_new_tokens\":500}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337aec2c-b067-4d50-818e-bc2168f28571",
      "metadata": {
        "id": "337aec2c-b067-4d50-818e-bc2168f28571"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c841c0-fc6a-477b-ab20-2dcd0586566a",
      "metadata": {
        "id": "68c841c0-fc6a-477b-ab20-2dcd0586566a"
      },
      "outputs": [],
      "source": [
        "loaded_documents = []\n",
        "\n",
        "for DATA_PATH in['drugLibTrain_raw.tsv','drugLibTest_raw.tsv']:\n",
        "    loader = CSVLoader(file_path=DATA_PATH, csv_args={'delimiter': '\\t'},source_column=\"condition\")\n",
        "    documents = loader.load()\n",
        "    loaded_documents.extend(documents)\n",
        "\n",
        "#DATA_PATH = 'drugs_for_common_treatments.csv'\n",
        "#loader = CSVLoader(file_path=DATA_PATH,source_column=\"drug_name\")\n",
        "#documents = loader.load()\n",
        "#loaded_documents.extend(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc861b2-f4b8-40dc-9744-12610be113d7",
      "metadata": {
        "id": "dfc861b2-f4b8-40dc-9744-12610be113d7"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "splits = text_splitter.split_documents(loaded_documents)\n",
        "\n",
        "model_name='sentence-transformers/all-MiniLM-L6-v2'\n",
        "#model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
        "                                       model_kwargs={'device': 'cpu'})\n",
        "\n",
        "#DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
        "vectorstore = FAISS.from_documents(splits, embeddings)\n",
        "#db.save_local(DB_FAISS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d469aa07-7787-4595-b362-fd458ea11947",
      "metadata": {
        "id": "d469aa07-7787-4595-b362-fd458ea11947"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts import HumanMessagePromptTemplate,SystemMessagePromptTemplate,ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec70495-c845-4d54-83e5-53c7f68a54f2",
      "metadata": {
        "id": "1ec70495-c845-4d54-83e5-53c7f68a54f2"
      },
      "source": [
        "## 1 Provide the summary of public reviews per drug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94dec764-20bf-4413-b369-589465241c9a",
      "metadata": {
        "id": "94dec764-20bf-4413-b369-589465241c9a"
      },
      "outputs": [],
      "source": [
        "#1serious\n",
        "general_system_template1 = r\"\"\"\n",
        "Act as a medical assistant, given the drug name - please provide the summary of all the reviews,\n",
        "highlighting the percent of negative and positive reviews.\n",
        "Please wish health and provide one fun proverb at the end.\n",
        " ----\n",
        "{context}\n",
        "----\n",
        "\"\"\"\n",
        "general_user_template1 = \"Question:```{question}```\"\n",
        "messages1 = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template1),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template1)\n",
        "]\n",
        "qa_prompt1 = ChatPromptTemplate.from_messages( messages1)\n",
        "chain1 = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True,\n",
        "                                             combine_docs_chain_kwargs={\"prompt\": qa_prompt1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "653e761f-c1d8-473a-9c45-4b78862cbd90",
      "metadata": {
        "id": "653e761f-c1d8-473a-9c45-4b78862cbd90"
      },
      "outputs": [],
      "source": [
        "#1playful\n",
        "general_system_template2 = r\"\"\"\n",
        "Act as a friend: calm me down and given the drug name - please provide the summary of all the reviews,\n",
        "in form of a funny story like I am a child.\n",
        "Please wish health and provide one fun proverb at the end.\n",
        " ----\n",
        "{context}\n",
        "----\n",
        "\"\"\"\n",
        "general_user_template2 = \"Question:```{question}```\"\n",
        "messages2 = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template2),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template2)\n",
        "]\n",
        "qa_prompt2 = ChatPromptTemplate.from_messages( messages2)\n",
        "chain2 = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True,\n",
        "                                             combine_docs_chain_kwargs={\"prompt\": qa_prompt2})\n",
        "\n",
        "llm_resp = {\"serious\" : chain1, \"playful\": chain2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8baa4216-73c7-4050-a61c-3a9c170b3ae7",
      "metadata": {
        "id": "8baa4216-73c7-4050-a61c-3a9c170b3ae7"
      },
      "outputs": [],
      "source": [
        "def give_summary(chain,query,chat_history = []):\n",
        "    #chat_history = [(query, result[\"answer\"])] #if we need to make a chatbot\n",
        "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "    return(md(result['answer']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e702f8-b846-4534-bf65-b152b1c2e8d5",
      "metadata": {
        "id": "86e702f8-b846-4534-bf65-b152b1c2e8d5"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48c6229-78d3-424a-97da-4cb8e855b2f2",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "70d35f483d7f44438966013af395a6a4",
            "e02e608c135e49e494b8f6b0c0ef7c61",
            "f04b97d8a7e44f25b8ec79f36e1da479",
            "cd679f76947d4ed2ac66eb5221b4b810"
          ]
        },
        "id": "f48c6229-78d3-424a-97da-4cb8e855b2f2",
        "outputId": "8dec02a2-b8bb-4525-95d0-8ae48c430934"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70d35f483d7f44438966013af395a6a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Drug name:', options=('abilify', 'accolate', 'accupril', 'accutane', 'aciphex', 'actiq',…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e02e608c135e49e494b8f6b0c0ef7c61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Summary:', options=('serious', 'playful'), value='serious')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f04b97d8a7e44f25b8ec79f36e1da479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='info', description='Give summary', icon='check', style=ButtonStyle(), tooltip='Run report…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd679f76947d4ed2ac66eb5221b4b810",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "drug_dropdown = widgets.Dropdown(\n",
        "    options=drugs,\n",
        "    value=drugs[0],\n",
        "    description='Drug name:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(drug_dropdown)\n",
        "\n",
        "llm_dropdown = widgets.Dropdown(\n",
        "    options=list(llm_resp.keys()),\n",
        "    value=list(llm_resp.keys())[0],\n",
        "    description='Summary:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(llm_dropdown)\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='Give summary',\n",
        "    disabled=False,\n",
        "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Run report',\n",
        "    icon='check'\n",
        ")\n",
        "display(button)\n",
        "\n",
        "out = widgets.Output(layout={'border': '1px solid black'})\n",
        "display(out)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        give_summary(llm_resp[llm_dropdown.value],drug_dropdown.value)\n",
        "        drug_url  = df2[df2['drug_name'].str.lower() == drug_dropdown.value.lower()][\"drug_link\"].head(1) #checking URL in the second dataset\n",
        "        if not drug_url.empty:\n",
        "            print(\"URL of the drug: \", drug_url.to_string(index=False, header=False))\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e907d710-acb4-46c4-8a54-776a1c50ffcb",
      "metadata": {
        "id": "e907d710-acb4-46c4-8a54-776a1c50ffcb"
      },
      "source": [
        "## 2 Compare public reviews per 2 drugs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddc2241-9e6b-4779-b173-0dbc2dc2a532",
      "metadata": {
        "id": "3ddc2241-9e6b-4779-b173-0dbc2dc2a532"
      },
      "outputs": [],
      "source": [
        "#1serious\n",
        "general_system_template2 = r\"\"\"\n",
        "Act as a medical assistant, given the 2 drug names separated by comma - compare  all the reviews,\n",
        "highlighting the percent of negative and positive reviews and sideeffects.\n",
        "At the end advice to consult with a health professional when choosing the best drug for you.\n",
        " ----\n",
        "{context}\n",
        "----\n",
        "\"\"\"\n",
        "general_user_template2 = \"Question:```{question}```\"\n",
        "messages2 = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template2),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template2)\n",
        "]\n",
        "qa_prompt2 = ChatPromptTemplate.from_messages( messages2)\n",
        "chain2 = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True,\n",
        "                                             combine_docs_chain_kwargs={\"prompt\": qa_prompt2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db36079b-e92b-476b-96b2-ec94d369f085",
      "metadata": {
        "id": "db36079b-e92b-476b-96b2-ec94d369f085"
      },
      "outputs": [],
      "source": [
        "#1playful\n",
        "general_system_template3 = r\"\"\"\n",
        "Act as a friend, given the 2 drug names separated by comma  - tell me a funny story about them\n",
        "helping me to better understand the posisitve and negative effects of these drugs on other people.\n",
        "At the end advice to consult with a health professional when choosing the best drug for you.\n",
        " ----\n",
        "{context}\n",
        "----\n",
        "\"\"\"\n",
        "general_user_template3 = \"Question:```{question}```\"\n",
        "messages3 = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template3),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template3)\n",
        "]\n",
        "qa_prompt3 = ChatPromptTemplate.from_messages( messages3)\n",
        "chain3 = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True,\n",
        "                                             combine_docs_chain_kwargs={\"prompt\": qa_prompt3})\n",
        "\n",
        "llm_resp1 = {\"serious\" : chain2, \"funny story\": chain3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea71c73-1db0-4ab9-9ea9-241fc4114749",
      "metadata": {
        "id": "0ea71c73-1db0-4ab9-9ea9-241fc4114749"
      },
      "outputs": [],
      "source": [
        "def compare_reviews(chain,drug1,drug2,chat_history = []):\n",
        "    query = f\"{drug1}, {drug2}\"\n",
        "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "    return(md(result['answer']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9024bce6-8daa-4516-995f-1bba2032351e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "39fd5a4d1a2d4a0f8a9f1b2fe4408d66",
            "88e078c8cffe462e8a2ea69555143e7a",
            "1235b89f062f4398bcc2603a99a746e7",
            "cb129a4bebcf4a57926e0295b43aa855",
            "c9044d23649f49a48c9ee2a1fb5bf913"
          ]
        },
        "id": "9024bce6-8daa-4516-995f-1bba2032351e",
        "outputId": "2ae76389-5bc3-4675-b3aa-ee427676fcb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39fd5a4d1a2d4a0f8a9f1b2fe4408d66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Drug name:', options=('abilify', 'accolate', 'accupril', 'accutane', 'aciphex', 'actiq',…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88e078c8cffe462e8a2ea69555143e7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Drug name:', options=('abilify', 'accolate', 'accupril', 'accutane', 'aciphex', 'actiq',…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1235b89f062f4398bcc2603a99a746e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Response:', options=('serious', 'funny story'), value='serious')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb129a4bebcf4a57926e0295b43aa855",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='info', description='Compare reviews', icon='check', style=ButtonStyle(), tooltip='Run rep…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9044d23649f49a48c9ee2a1fb5bf913",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "drug_dropdown1 = widgets.Dropdown(\n",
        "    options=drugs,\n",
        "    value=drugs[0],\n",
        "    description='Drug name:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(drug_dropdown1)\n",
        "\n",
        "drug_dropdown2 = widgets.Dropdown(\n",
        "    options=drugs,\n",
        "    value=drugs[0],\n",
        "    description='Drug name:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(drug_dropdown2)\n",
        "\n",
        "llm_dropdown1 = widgets.Dropdown(\n",
        "    options=list(llm_resp1.keys()),\n",
        "    value=list(llm_resp1.keys())[0],\n",
        "    description='Response:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(llm_dropdown1)\n",
        "\n",
        "button1 = widgets.Button(\n",
        "    description='Compare reviews',\n",
        "    disabled=False,\n",
        "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Run report',\n",
        "    icon='check'\n",
        ")\n",
        "display(button1)\n",
        "\n",
        "out1 = widgets.Output(layout={'border': '1px solid black'})\n",
        "display(out1)\n",
        "\n",
        "def on_button_clicked1(b):\n",
        "    with out1:\n",
        "        out1.clear_output()\n",
        "        compare_reviews(llm_resp1[llm_dropdown1.value],drug_dropdown1.value,drug_dropdown2.value)\n",
        "\n",
        "\n",
        "button1.on_click(on_button_clicked1, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d5da23-cefd-4b37-85a0-d2d60745567d",
      "metadata": {
        "id": "d5d5da23-cefd-4b37-85a0-d2d60745567d"
      },
      "source": [
        "## 2 List top 3 drugs for given condition and summary of their reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3271c4f-379d-4055-94dd-923357cab465",
      "metadata": {
        "id": "a3271c4f-379d-4055-94dd-923357cab465"
      },
      "outputs": [],
      "source": [
        "#1serious\n",
        "general_system_template3 = r\"\"\"\n",
        "Act as a medical assistant, given the condition - show top 3 drugs for this condition according to the user reviews.\n",
        "Show negative and positive side effects and advice to consult to professional at the end.\n",
        "\n",
        " ----\n",
        "{context}\n",
        "----\n",
        "\"\"\"\n",
        "general_user_template3 = \"Question:```{question}```\"\n",
        "messages3 = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template3),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template3)\n",
        "]\n",
        "qa_prompt3 = ChatPromptTemplate.from_messages( messages3)\n",
        "chain3 = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True,\n",
        "                                             combine_docs_chain_kwargs={\"prompt\": qa_prompt3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cab0e31-637d-432a-8e10-a9ed0224e66b",
      "metadata": {
        "id": "6cab0e31-637d-432a-8e10-a9ed0224e66b"
      },
      "outputs": [],
      "source": [
        "#1game\n",
        "general_system_template4 = r\"\"\"\n",
        "Act as a friend, given the condition - create a fun game scenario teaching about the top 3 drugs for this condition.\n",
        "Advice to consult to professional at the end.\n",
        "\n",
        " ----\n",
        "{context}\n",
        "----\n",
        "\"\"\"\n",
        "general_user_template4 = \"Question:```{question}```\"\n",
        "messages4 = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template4),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template4)\n",
        "]\n",
        "qa_prompt4 = ChatPromptTemplate.from_messages( messages4)\n",
        "chain4 = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True,\n",
        "                                             combine_docs_chain_kwargs={\"prompt\": qa_prompt4})\n",
        "\n",
        "llm_resp2 = {\"serious\" : chain3, \"game\": chain4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b01a256a-5e21-4b59-bb7a-a412c02f1f95",
      "metadata": {
        "id": "b01a256a-5e21-4b59-bb7a-a412c02f1f95"
      },
      "outputs": [],
      "source": [
        "def drug_for_condition(chain,condition,chat_history = []):\n",
        "    query = condition\n",
        "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "    return(md(result['answer']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c10a1b1-2e83-4314-92e0-8b4cb999ac04",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "818688c8415b455e9b6638b89c0debac",
            "884b81e765dd4b98b2598e8175720a2e",
            "3017559856964ec7bfca4875e936b1df",
            "a84d43ae8f0c4da39592e1284f31c5d7"
          ]
        },
        "id": "4c10a1b1-2e83-4314-92e0-8b4cb999ac04",
        "outputId": "117639ac-61cc-4a1b-8ebd-90bfa4b87e06"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "818688c8415b455e9b6638b89c0debac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Condition:', options=('acid reflux', 'acne', 'add', 'adhd', 'adult acne', 'allergies', '…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "884b81e765dd4b98b2598e8175720a2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Top 3 drugs:', options=('serious', 'game'), value='serious')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3017559856964ec7bfca4875e936b1df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='info', description='Give top 3 drugs', icon='check', style=ButtonStyle(), tooltip='Run re…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a84d43ae8f0c4da39592e1284f31c5d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "condition_dropdown = widgets.Dropdown(\n",
        "    options=conditions,\n",
        "    value=conditions[0],\n",
        "    description='Condition:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(condition_dropdown)\n",
        "\n",
        "llm_dropdown2 = widgets.Dropdown(\n",
        "    options=list(llm_resp2.keys()),\n",
        "    value=list(llm_resp2.keys())[0],\n",
        "    description='Top 3 drugs:',\n",
        "    disabled=False,\n",
        ")\n",
        "display(llm_dropdown2)\n",
        "\n",
        "button2 = widgets.Button(\n",
        "    description='Give top 3 drugs',\n",
        "    disabled=False,\n",
        "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Run report',\n",
        "    icon='check'\n",
        ")\n",
        "display(button2)\n",
        "\n",
        "out2 = widgets.Output(layout={'border': '1px solid black'})\n",
        "display(out2)\n",
        "\n",
        "def on_button_clicked2(b):\n",
        "    with out2:\n",
        "        out2.clear_output()\n",
        "        drug_for_condition(llm_resp2[llm_dropdown2.value],condition_dropdown.value)\n",
        "\n",
        "\n",
        "button2.on_click(on_button_clicked2, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2604f16-2cc5-49c5-81f6-1c696a556120",
      "metadata": {
        "id": "d2604f16-2cc5-49c5-81f6-1c696a556120"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}